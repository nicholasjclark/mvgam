â„¹ Loading mvgam
Loading required package: brms
Loading required package: Rcpp
Loading 'brms' package (version 2.22.9). Useful instructions
can be found by typing help('brms'). A more detailed introduction
to the package is available through vignette('brms_overview').

Attaching package: 'brms'

The following object is masked from 'package:stats':

    ar

Loading 'mvgam' (version 2.0.0). Useful instructions can be found by
  typing help('mvgam'). A more detailed introduction to the package is
  available through vignette('mvgam_overview'). Full brms compatibility is
  now enabled.
Setting up test data...

=== Fitting Model 1: Basic RW ===
Fit 1 completed in 38.5 seconds
GAM observation formula:
y ~ x

GAM process formula:
trend_y ~ 0
<environment: 0x000001403f070b50>


Family:
poisson 

Link function:
log 


Trend model:
RW 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 1 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> K;
  matrix[N, K] X;
  int<lower=1> Kc;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
  vector[1] mu_ones;
}
transformed data {
  matrix[N, Kc] Xc;
  vector[Kc] means_X;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  for (i in 2 : K) {
    means_X[i - 1] = mean(X[ : , i]);
    Xc[ : , i - 1] = X[ : , i] - means_X[i - 1];
  }
}
parameters {
  vector[Kc] b;
  real Intercept;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  lv_trend[1,  : ] = scaled_innovations_trend[1,  : ];
  for (i in 2 : N_trend) {
    lv_trend[i,  : ] = lv_trend[i - 1,  : ]
                       + scaled_innovations_trend[i,  : ];
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Xc * b;
    mu += Intercept;
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    // Likelihood calculations
    target += poisson_log_glm_lpmf(Y | to_matrix(mu), 0.0, mu_ones);
  }
  
  // Prior contributions
  target += lprior;
}
generated quantities {
  real b_Intercept = Intercept - dot_product(means_X, b);
}

--- END STANCODE ---

Saved to tasks/fixtures/fit1.rds

=== Fitting Model 2: Multivariate shared RW ===
Fit 2 completed in 41.6 seconds
GAM observation formula:
count ~ x 
biomass ~ x 

GAM process formula:
trend_y ~ 0
<environment: 0x0000013faeb3b3f8>


Family:
gaussian 

Link function:
identity 


Trend model:
RW 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 2 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  
}
data {
  int<lower=1> N;
  int<lower=1> N_count;
  vector[N_count] Y_count;
  int<lower=1> K_count;
  matrix[N_count, K_count] X_count;
  int<lower=1> Kc_count;
  int<lower=1> N_biomass;
  vector[N_biomass] Y_biomass;
  int<lower=1> K_biomass;
  matrix[N_biomass, K_biomass] X_biomass;
  int<lower=1> Kc_biomass;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N_count] int obs_trend_time_count;
  array[N_count] int obs_trend_series_count;
  array[N_biomass] int obs_trend_time_biomass;
  array[N_biomass] int obs_trend_series_biomass;
  vector[1] mu_ones_count;
  vector[1] mu_ones_biomass;
}
transformed data {
  matrix[N_count, Kc_count] Xc_count;
  vector[Kc_count] means_X_count;
  matrix[N_biomass, Kc_biomass] Xc_biomass;
  vector[Kc_biomass] means_X_biomass;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  for (i in 2 : K_count) {
    means_X_count[i - 1] = mean(X_count[ : , i]);
    Xc_count[ : , i - 1] = X_count[ : , i] - means_X_count[i - 1];
  }
  for (i in 2 : K_biomass) {
    means_X_biomass[i - 1] = mean(X_biomass[ : , i]);
    Xc_biomass[ : , i - 1] = X_biomass[ : , i] - means_X_biomass[i - 1];
  }
}
parameters {
  vector[Kc_count] b_count;
  real Intercept_count;
  real<lower=0> sigma_count;
  vector[Kc_biomass] b_biomass;
  real Intercept_biomass;
  real<lower=0> sigma_biomass;
  vector<lower=0>[N_lv_trend] sigma_trend;
  cholesky_factor_corr[N_lv_trend] L_Omega_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept_count | 3, 3, 2.5);
  lprior += student_t_lpdf(sigma_count | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(Intercept_biomass | 3, 2.7, 2.5);
  lprior += student_t_lpdf(sigma_biomass | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  {
    matrix[N_lv_trend, N_lv_trend] L_Sigma = diag_pre_multiply(sigma_trend,
                                                               L_Omega_trend);
    scaled_innovations_trend = innovations_trend * L_Sigma';
  }
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  matrix[N_lv_trend, N_lv_trend] Sigma_trend = diag_pre_multiply(sigma_trend,
                                                                 L_Omega_trend);
  lv_trend[1,  : ] = scaled_innovations_trend[1,  : ];
  for (i in 2 : N_trend) {
    lv_trend[i,  : ] = lv_trend[i - 1,  : ]
                       + scaled_innovations_trend[i,  : ];
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  L_Omega_trend ~ lkj_corr_cholesky(2);
  to_vector(innovations_trend) ~ std_normal();
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N_biomass] mu_biomass = Xc_biomass * b_biomass;
    for (n in 1 : N_biomass) {
      mu_biomass[n] += Intercept_biomass
                       + trend[obs_trend_time_biomass[n], obs_trend_series_biomass[n]];
    }
    vector[N_count] mu_count = Xc_count * b_count;
    for (n in 1 : N_count) {
      mu_count[n] += Intercept_count
                     + trend[obs_trend_time_count[n], obs_trend_series_count[n]];
    }
    // Likelihood calculations
    target += normal_id_glm_lpdf(Y_count | to_matrix(mu_count), 0.0, mu_ones_count, sigma_count);
    target += normal_id_glm_lpdf(Y_biomass | to_matrix(mu_biomass), 0.0, mu_ones_biomass, sigma_biomass);
  }
  
  // Prior contributions
  target += lprior;
}
generated quantities {
  real b_count_Intercept = Intercept_count
                           - dot_product(means_X_count, b_count);
  real b_biomass_Intercept = Intercept_biomass
                             - dot_product(means_X_biomass, b_biomass);
}

--- END STANCODE ---

Saved to tasks/fixtures/fit2.rds

=== Fitting Model 3: VARMA with smooths ===
DEBUG: Taking FALLBACK PATH (4-case logic)
DEBUG: has_coefficients = TRUE 
DEBUG: Case 3 - Covariates only ( X_trend * b _trend )
DEBUG: Generated mu_trend_code:
 vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  mu_trend += X_trend * b_trend; 
Fit 3 completed in 269.6 seconds
GAM observation formula:
count ~ s(x) 
biomass ~ s(x) 

GAM process formula:
trend_y ~ presence - 1


Family:
gaussian 

Link function:
identity 


Trend model:
VAR 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 3 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  matrix sqrtm(matrix A) {
    int m = rows(A);
    vector[m] eigenvals = eigenvalues_sym(A);
    
    // Numerical stability check for positive definiteness
    if (min(eigenvals) <= 1e-12) {
      reject("Matrix must be positive definite for square root computation");
    }
    vector[m] root_root_evals = sqrt(sqrt(eigenvals));
    matrix[m, m] evecs = eigenvectors_sym(A);
    matrix[m, m] eprod = diag_post_multiply(evecs, root_root_evals);
    return tcrossprod(eprod);
  }
  matrix AtoP(matrix P_real) {
    int m = rows(P_real);
    matrix[m, m] B = tcrossprod(P_real);
    for (i in 1 : m) {
      B[i, i] += 1.0;
    }
    return mdivide_left_spd(sqrtm(B), P_real);
  }
  matrix kronecker_prod(matrix A, matrix B) {
    int m = rows(A);
    int n = cols(A);
    int p = rows(B);
    int q = cols(B);
    matrix[m * p, n * q] C;
    for (i in 1 : m) {
      for (j in 1 : n) {
        int row_start = (i - 1) * p + 1;
        int row_end = (i - 1) * p + p;
        int col_start = (j - 1) * q + 1;
        int col_end = (j - 1) * q + q;
        C[row_start : row_end, col_start : col_end] = A[i, j] * B;
      }
    }
    return C;
  }
  array[,] matrix rev_mapping(array[] matrix P, matrix Sigma) {
    int p = size(P);
    int m = rows(Sigma);
    array[p, p] matrix[m, m] phi_for;
    array[p, p] matrix[m, m] phi_rev;
    array[p + 1] matrix[m, m] Sigma_for;
    array[p + 1] matrix[m, m] Sigma_rev;
    matrix[m, m] S_for;
    matrix[m, m] S_rev;
    array[p + 1] matrix[m, m] S_for_list;
    array[p + 1] matrix[m, m] Gamma_trans;
    array[2, p] matrix[m, m] phiGamma;
    Sigma_for[p + 1] = Sigma;
    S_for_list[p + 1] = sqrtm(Sigma);
    for (s in 1 : p) {
      S_for = -tcrossprod(P[p - s + 1]);
      for (i in 1 : m) {
        S_for[i, i] += 1.0;
      }
      S_rev = sqrtm(S_for);
      S_for_list[p - s + 1] = mdivide_right_spd(mdivide_left_spd(S_rev,
                                                                 sqrtm(
                                                                 quad_form_sym(
                                                                 Sigma_for[
                                                                 p - s + 2],
                                                                 S_rev))),
                                                S_rev);
      Sigma_for[p - s + 1] = tcrossprod(S_for_list[p - s + 1]);
    }
    Sigma_rev[1] = Sigma_for[1];
    Gamma_trans[1] = Sigma_for[1];
    for (s in 0 : (p - 1)) {
      S_for = S_for_list[s + 1];
      S_rev = sqrtm(Sigma_rev[s + 1]);
      phi_for[s + 1, s + 1] = mdivide_right_spd(S_for * P[s + 1], S_rev);
      phi_rev[s + 1, s + 1] = mdivide_right_spd(S_rev * P[s + 1]', S_for);
      Gamma_trans[s + 2] = phi_for[s + 1, s + 1] * Sigma_rev[s + 1];
      if (s >= 1) {
        for (k in 1 : s) {
          phi_for[s + 1, k] = phi_for[s, k]
                              - phi_for[s + 1, s + 1] * phi_rev[s, s - k + 1];
          phi_rev[s + 1, k] = phi_rev[s, k]
                              - phi_rev[s + 1, s + 1] * phi_for[s, s - k + 1];
        }
        for (k in 1 : s) {
          Gamma_trans[s + 2] = Gamma_trans[s + 2]
                               + phi_for[s, k] * Gamma_trans[s + 2 - k];
        }
      }
      Sigma_rev[s + 2] = Sigma_rev[s + 1]
                         - quad_form_sym(Sigma_for[s + 1],
                                         phi_rev[s + 1, s + 1]');
    }
    for (i in 1 : p) {
      phiGamma[1, i] = phi_for[p, i];
      phiGamma[2, i] = Gamma_trans[i]';
    }
    return phiGamma;
  }
  matrix initial_joint_var(matrix Sigma, array[] matrix phi,
                           array[] matrix theta) {
    int p = size(phi);
    int q = size(theta);
    int m = rows(Sigma);
    matrix[(p + q) * m, (p + q) * m] companion_mat = rep_matrix(0.0,
                                                                (p + q) * m,
                                                                (p + q) * m);
    matrix[(p + q) * m, (p + q) * m] companion_var = rep_matrix(0.0,
                                                                (p + q) * m,
                                                                (p + q) * m);
    matrix[(p + q) * m * (p + q) * m, (p + q) * m * (p + q) * m] tmp;
    matrix[(p + q) * m, (p + q) * m] Omega;
    for (i in 1 : p) {
      companion_mat[1 : m, ((i - 1) * m + 1) : (i * m)] = phi[i];
      if (i > 1) {
        for (j in 1 : m) {
          companion_mat[(i - 1) * m + j, (i - 2) * m + j] = 1.0;
        }
      }
    }
    for (i in 1 : q) {
      companion_mat[1 : m, ((p + i - 1) * m + 1) : ((p + i) * m)] = theta[i];
    }
    if (q > 1) {
      for (i in 2 : q) {
        for (j in 1 : m) {
          companion_mat[(p + i - 1) * m + j, (p + i - 2) * m + j] = 1.0;
        }
      }
    }
    companion_var[1 : m, 1 : m] = Sigma;
    companion_var[(p * m + 1) : ((p + 1) * m), (p * m + 1) : ((p + 1) * m)] = Sigma;
    companion_var[1 : m, (p * m + 1) : ((p + 1) * m)] = Sigma;
    companion_var[(p * m + 1) : ((p + 1) * m), 1 : m] = Sigma;
    tmp = diag_matrix(rep_vector(1.0, (p + q) * m * (p + q) * m))
          - kronecker_prod(companion_mat, companion_mat);
    Omega = to_matrix(tmp \ to_vector(companion_var), (p + q) * m,
                      (p + q) * m);
    for (i in 1 : (rows(Omega) - 1)) {
      for (j in (i + 1) : rows(Omega)) {
        Omega[j, i] = Omega[i, j];
      }
    }
    return Omega;
  }
}
data {
  int<lower=1> N;
  int<lower=1> N_count;
  vector[N_count] Y_count;
  int Ks_count;
  matrix[N_count, Ks_count] Xs_count;
  int nb_count_1;
  array[nb_count_1] int knots_count_1;
  matrix[N_count, knots_count_1[1]] Zs_count_1_1;
  int<lower=1> N_biomass;
  vector[N_biomass] Y_biomass;
  int Ks_biomass;
  matrix[N_biomass, Ks_biomass] Xs_biomass;
  int nb_biomass_1;
  array[nb_biomass_1] int knots_biomass_1;
  matrix[N_biomass, knots_biomass_1[1]] Zs_biomass_1_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  int<lower=1> K_trend;
  matrix[N_trend, K_trend] X_trend;
  array[N_count] int obs_trend_time_count;
  array[N_count] int obs_trend_series_count;
  array[N_biomass] int obs_trend_time_biomass;
  array[N_biomass] int obs_trend_series_biomass;
}
transformed data {
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  vector[N_lv_trend] trend_zeros = rep_vector(0.0, N_lv_trend);
}
parameters {
  real Intercept_count;
  vector[Ks_count] bs_count;
  vector[knots_count_1[1]] zs_count_1_1;
  vector<lower=0>[nb_count_1] sds_count_1;
  real<lower=0> sigma_count;
  real Intercept_biomass;
  vector[Ks_biomass] bs_biomass;
  vector[knots_biomass_1[1]] zs_biomass_1_1;
  vector<lower=0>[nb_biomass_1] sds_biomass_1;
  real<lower=0> sigma_biomass;
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  vector[K_trend] b_trend;
  array[2] matrix[N_lv_trend, N_lv_trend] A_raw_trend;
  vector<lower=0>[N_lv_trend] sigma_trend;
  cholesky_factor_corr[N_lv_trend] L_Omega_trend;
  array[2] vector[2] Amu_trend;
  array[2] vector<lower=0>[2] Aomega_trend;
  vector[(2 + 1) * N_lv_trend] init_trend;
  array[1] matrix[N_lv_trend, N_lv_trend] D_raw_trend;
  array[2] vector[1] Dmu_trend;
  array[2] vector<lower=0>[1] Domega_trend;
}
transformed parameters {
  vector[knots_count_1[1]] s_count_1_1;
  vector[knots_biomass_1[1]] s_biomass_1_1;
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept_count | 3, 3, 2.5);
  lprior += student_t_lpdf(sds_count_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sigma_count | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(Intercept_biomass | 3, 2.7, 2.5);
  lprior += student_t_lpdf(sds_biomass_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sigma_biomass | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  mu_trend += X_trend * b_trend;
  matrix[N_lv_trend, N_lv_trend] L_Sigma_trend = diag_pre_multiply(sigma_trend,
                                                                   L_Omega_trend);
  cov_matrix[N_lv_trend] Sigma_trend = multiply_lower_tri_self_transpose(L_Sigma_trend);
  array[2] matrix[N_lv_trend, N_lv_trend] A_trend;
  array[2] matrix[N_lv_trend, N_lv_trend] P_var;
  array[2, 2] matrix[N_lv_trend, N_lv_trend] result_var;
  for (i in 1 : 2) {
    P_var[i] = AtoP(A_raw_trend[i]);
  }
  result_var = rev_mapping(P_var, Sigma_trend);
  for (i in 1 : 2) {
    A_trend[i] = result_var[1, i];
  }
  array[1] matrix[N_lv_trend, N_lv_trend] D_trend;
  cov_matrix[(2 + 1) * N_lv_trend] Omega_trend;
  vector[N_lv_trend] ma_init_trend;
  array[1] matrix[N_lv_trend, N_lv_trend] P_ma;
  array[2, 1] matrix[N_lv_trend, N_lv_trend] result_ma;
  for (i in 1 : 1) {
    P_ma[i] = AtoP(D_raw_trend[i]);
  }
  result_ma = rev_mapping(P_ma, Sigma_trend);
  for (i in 1 : 1) {
    D_trend[i] = -result_ma[1, i];
  }
  Omega_trend = initial_joint_var(Sigma_trend, A_trend, D_trend);
  ma_init_trend = init_trend[(2 * N_lv_trend + 1) : (3 * N_lv_trend)];
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
  s_count_1_1 = sds_count_1[1] * zs_count_1_1;
  s_biomass_1_1 = sds_biomass_1[1] * zs_biomass_1_1;
}
model {
  vector[(2 + 1) * N_lv_trend] mu_init_trend = rep_vector(0.0,
                                                          (2 + 1)
                                                          * N_lv_trend);
  init_trend ~ multi_normal(mu_init_trend, Omega_trend);
  array[N_trend] vector[N_lv_trend] mu_t_trend;
  for (t in 1 : N_trend) {
    mu_t_trend[t] = rep_vector(0.0, N_lv_trend);
    for (i in 1 : 2) {
      if (t - i <= 0) {
        int init_idx = 2 + 1 - i;
        if (init_idx > 0 && init_idx <= 2) {
          vector[N_lv_trend] lagged_lv;
          int start_idx = (init_idx - 1) * N_lv_trend + 1;
          int end_idx = init_idx * N_lv_trend;
          lagged_lv = init_trend[start_idx : end_idx];
          mu_t_trend[t] += A_trend[i] * lagged_lv;
        }
      } else {
        mu_t_trend[t] += A_trend[i] * lv_trend[t - i,  : ]';
      }
    }
    if (t - 1 <= 0) {
      mu_t_trend[t] += D_trend[1] * ma_init_trend;
    } else {
      mu_t_trend[t] += D_trend[1]
                       * (lv_trend[t - 1,  : ]' - mu_t_trend[t - 1]);
    }
  }
  for (t in 1 : N_trend) {
    lv_trend[t,  : ]' ~ multi_normal(mu_t_trend[t], Sigma_trend);
  }
  for (lag in 1 : 2) {
    diagonal(A_raw_trend[lag]) ~ normal(Amu_trend[1, lag],
                                        1 / sqrt(Aomega_trend[1, lag]));
    for (i in 1 : N_lv_trend) {
      for (j in 1 : N_lv_trend) {
        if (i != j) {
          A_raw_trend[lag, i, j] ~ normal(Amu_trend[2, lag],
                                          1 / sqrt(Aomega_trend[2, lag]));
        }
      }
    }
  }
  for (ma_lag in 1 : 1) {
    diagonal(D_raw_trend[ma_lag]) ~ normal(Dmu_trend[1, ma_lag],
                                           1 / sqrt(Domega_trend[1, ma_lag]));
    for (i in 1 : N_lv_trend) {
      for (j in 1 : N_lv_trend) {
        if (i != j) {
          D_raw_trend[ma_lag, i, j] ~ normal(Dmu_trend[2, ma_lag],
                                             1
                                             / sqrt(Domega_trend[2, ma_lag]));
        }
      }
    }
  }
  Dmu_trend[1, 1] ~ normal(0.0, 1.0);
  Domega_trend[1, 1] ~ gamma(2.0, 1.0);
  Dmu_trend[2, 1] ~ normal(0.0, 1.0);
  Domega_trend[2, 1] ~ gamma(2.0, 1.0);
  L_Omega_trend ~ lkj_corr_cholesky(2);
  for (lag in 1 : 2) {
    Amu_trend[lag] ~ normal(0, sqrt(0.455));
    Aomega_trend[lag] ~ gamma(1.365, 0.071175);
  }
  sigma_trend ~ exponential(2);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N_count] mu_count = rep_vector(0.0, N_count);
    vector[N_biomass] mu_biomass = rep_vector(0.0, N_biomass);
    mu_count += Intercept_count + Xs_count * bs_count
                + Zs_count_1_1 * s_count_1_1;
    for (n in 1 : N_count) {
      mu_count[n] += trend[obs_trend_time_count[n], obs_trend_series_count[n]];
    }
    mu_biomass += Intercept_biomass + Xs_biomass * bs_biomass
                  + Zs_biomass_1_1 * s_biomass_1_1;
    for (n in 1 : N_biomass) {
      mu_biomass[n] += trend[obs_trend_time_biomass[n], obs_trend_series_biomass[n]];
    }
    // Likelihood calculations
    target += normal_lpdf(Y_count | mu_count, sigma_count);
    target += normal_lpdf(Y_biomass | mu_biomass, sigma_biomass);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(zs_count_1_1);
  target += std_normal_lpdf(zs_biomass_1_1);
}
generated quantities {
  real b_count_Intercept = Intercept_count;
  real b_biomass_Intercept = Intercept_biomass;
}

--- END STANCODE ---

Saved to tasks/fixtures/fit3.rds

=== Fitting Model 4: Factor AR ===
Fit 4 completed in 48.4 seconds
GAM observation formula:
count ~ x 
presence ~ x 
biomass ~ x 

GAM process formula:
trend_y ~ 0
<environment: 0x000001403b568d98>


Family:
gaussian 

Link function:
identity 


Trend model:
AR 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 4 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  
}
data {
  int<lower=1> N;
  int<lower=1> N_count;
  array[N_count] int Y_count;
  int<lower=1> K_count;
  matrix[N_count, K_count] X_count;
  int<lower=1> Kc_count;
  int<lower=1> N_presence;
  array[N_presence] int Y_presence;
  int<lower=1> K_presence;
  matrix[N_presence, K_presence] X_presence;
  int<lower=1> Kc_presence;
  int<lower=1> N_biomass;
  vector[N_biomass] Y_biomass;
  int<lower=1> K_biomass;
  matrix[N_biomass, K_biomass] X_biomass;
  int<lower=1> Kc_biomass;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N_count] int obs_trend_time_count;
  array[N_count] int obs_trend_series_count;
  array[N_presence] int obs_trend_time_presence;
  array[N_presence] int obs_trend_series_presence;
  array[N_biomass] int obs_trend_time_biomass;
  array[N_biomass] int obs_trend_series_biomass;
  vector[1] mu_ones_count;
  vector[1] mu_ones_presence;
}
transformed data {
  matrix[N_count, Kc_count] Xc_count;
  vector[Kc_count] means_X_count;
  matrix[N_presence, Kc_presence] Xc_presence;
  vector[Kc_presence] means_X_presence;
  matrix[N_biomass, Kc_biomass] Xc_biomass;
  vector[Kc_biomass] means_X_biomass;
  for (i in 2 : K_count) {
    means_X_count[i - 1] = mean(X_count[ : , i]);
    Xc_count[ : , i - 1] = X_count[ : , i] - means_X_count[i - 1];
  }
  for (i in 2 : K_presence) {
    means_X_presence[i - 1] = mean(X_presence[ : , i]);
    Xc_presence[ : , i - 1] = X_presence[ : , i] - means_X_presence[i - 1];
  }
  for (i in 2 : K_biomass) {
    means_X_biomass[i - 1] = mean(X_biomass[ : , i]);
    Xc_biomass[ : , i - 1] = X_biomass[ : , i] - means_X_biomass[i - 1];
  }
}
parameters {
  vector[Kc_count] b_count;
  real Intercept_count;
  vector[Kc_presence] b_presence;
  real Intercept_presence;
  vector[Kc_biomass] b_biomass;
  real Intercept_biomass;
  real<lower=0> shape_biomass;
  vector<lower=0>[N_lv_trend] sigma_trend;
  cholesky_factor_corr[N_lv_trend] L_Omega_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
  vector[N_series_trend * N_lv_trend] Z_raw;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept_count | 3, 1.1, 2.5);
  lprior += student_t_lpdf(Intercept_presence | 3, 0, 2.5);
  lprior += student_t_lpdf(Intercept_biomass | 3, 1, 2.5);
  lprior += gamma_lpdf(shape_biomass | 0.01, 0.01);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  {
    matrix[N_lv_trend, N_lv_trend] L_Sigma = diag_pre_multiply(sigma_trend,
                                                               L_Omega_trend);
    scaled_innovations_trend = innovations_trend * L_Sigma';
  }
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = rep_matrix(0, N_series_trend,
                                                    N_lv_trend);
  {
    int index = 1;
    for (j in 1 : N_lv_trend) {
      for (i in j : N_series_trend) {
        Z[i, j] = Z_raw[index];
        index += 1;
      }
    }
  }
  matrix[N_lv_trend, N_lv_trend] Sigma_trend = diag_pre_multiply(sigma_trend,
                                                                 L_Omega_trend);
  for (i in 1 : 1) {
    lv_trend[i,  : ] = scaled_innovations_trend[i,  : ];
  }
  for (i in 2 : N_trend) {
    for (j in 1 : N_lv_trend) {
      lv_trend[i, j] = ar1_trend[j] * lv_trend[i - 1, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  L_Omega_trend ~ lkj_corr_cholesky(2);
  to_vector(innovations_trend) ~ std_normal();
  ar1_trend ~ normal(0, 0.5);
  Z_raw ~ student_t(3, 0, 1);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N_presence] mu_presence = Xc_presence * b_presence;
    for (n in 1 : N_presence) {
      mu_presence[n] += Intercept_presence
                        + trend[obs_trend_time_presence[n], obs_trend_series_presence[n]];
    }
    vector[N_count] mu_count = Xc_count * b_count;
    for (n in 1 : N_count) {
      mu_count[n] += Intercept_count
                     + trend[obs_trend_time_count[n], obs_trend_series_count[n]];
    }
    vector[N_biomass] mu_biomass = rep_vector(0.0, N_biomass);
    mu_biomass += Intercept_biomass + Xc_biomass * b_biomass;
    for (n in 1 : N_biomass) {
      mu_biomass[n] += trend[obs_trend_time_biomass[n], obs_trend_series_biomass[n]];
    }
    mu_biomass = exp(mu_biomass);
    // Likelihood calculations
    target += poisson_log_glm_lpmf(Y_count | to_matrix(mu_count), 0.0, mu_ones_count);
    target += bernoulli_logit_glm_lpmf(Y_presence | to_matrix(mu_presence), 0.0, mu_ones_presence);
    target += gamma_lpdf(Y_biomass | shape_biomass, shape_biomass
                                                    ./ mu_biomass);
  }
  
  // Prior contributions
  target += lprior;
}
generated quantities {
  real b_count_Intercept = Intercept_count
                           - dot_product(means_X_count, b_count);
  real b_presence_Intercept = Intercept_presence
                              - dot_product(means_X_presence, b_presence);
  real b_biomass_Intercept = Intercept_biomass
                             - dot_product(means_X_biomass, b_biomass);
}

--- END STANCODE ---

Saved to tasks/fixtures/fit4.rds

=== Fitting Model 5: Piecewise trends ===
Fit 5 completed in 34.4 seconds
GAM observation formula:
y ~ x

GAM process formula:
trend_y ~ 0
<environment: 0x000001403d84c2e0>


Family:
poisson 

Link function:
log 


Trend model:
PW 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 5 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  matrix get_changepoint_matrix(vector t, vector t_change_trend, int T, int S) {
    /* Function to sort changepoints */
    
    /* credit goes to the Prophet development team at Meta */
    matrix[T, S] Kappa;
    row_vector[S] a_row;
    int cp_idx;
    Kappa = rep_matrix(0, T, S);
    a_row = rep_row_vector(0, S);
    cp_idx = 1;
    for (i in 1 : T) {
      while ((cp_idx <= S) && (t[i] >= t_change_trend[cp_idx])) {
        a_row[cp_idx] = 1;
        cp_idx = cp_idx + 1;
      }
      Kappa[i] = a_row;
    }
    return Kappa;
  }
  vector logistic_gamma(real k, real m, vector delta, vector t_change_trend,
                        int S) {
    /* Function to compute a logistic trend with changepoints */
    /* credit goes to the Prophet development team at Meta */
    vector[S] gamma;
    vector[S + 1] k_s;
    real m_pr;
    k_s = append_row(k, k + cumulative_sum(delta));
    m_pr = m;
    for (i in 1 : S) {
      gamma[i] = (t_change_trend[i] - m_pr) * (1 - k_s[i] / k_s[i + 1]);
      m_pr = m_pr + gamma[i];
    }
    return gamma;
  }
  vector logistic_trend(real k, real m, vector delta, vector t,
                        vector cap_trend, matrix Kappa_trend,
                        vector t_change_trend, int S) {
    /* Function to adjust a logistic trend using a carrying capacity */
    /* credit goes to the Prophet development team at Meta */
    vector[S] gamma;
    gamma = logistic_gamma(k, m, delta, t_change_trend, S);
    return cap_trend
           .* inv_logit((k + Kappa_trend * delta)
                        .* (t - (m + Kappa_trend * gamma)));
  }
  vector linear_trend(real k, real m, vector delta, vector t,
                      matrix Kappa_trend, vector t_change_trend) {
    /* Function to compute a linear trend with changepoints */
    /* credit goes to the Prophet development team at Meta */
    return (k + Kappa_trend * delta) .* t
           + (m + Kappa_trend * (-t_change_trend .* delta));
  }
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> K;
  matrix[N, K] X;
  int<lower=1> Kc;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
  int<lower=0> n_change_trend;
  vector[n_change_trend] t_change_trend;
  real<lower=0> change_scale_trend;
  vector[1] mu_ones;
}
transformed data {
  matrix[N, Kc] Xc;
  vector[Kc] means_X;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  vector[N_trend] time_trend;
  for (i in 1 : N_trend) 
    time_trend[i] = i;
  matrix[N_trend, n_change_trend] Kappa_trend = get_changepoint_matrix(time_trend,
                                                                    t_change_trend,
                                                                    N_trend,
                                                                    n_change_trend);
  for (i in 2 : K) {
    means_X[i - 1] = mean(X[ : , i]);
    Xc[ : , i - 1] = X[ : , i] - means_X[i - 1];
  }
}
parameters {
  vector[Kc] b;
  real Intercept;
  vector[N_lv_trend] k_trend;
  vector[N_lv_trend] m_trend;
  matrix[n_change_trend, N_lv_trend] delta_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  for (s in 1 : N_lv_trend) {
    lv_trend[1 : N_trend, s] = linear_trend(k_trend[s], m_trend[s],
                                            to_vector(delta_trend[ : , s]),
                                            time_trend, Kappa_trend,
                                            t_change_trend);
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  m_trend ~ student_t(3, 0, 2.5);
  k_trend ~ std_normal();
  to_vector(delta_trend) ~ double_exponential(0, 0.05);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Xc * b;
    mu += Intercept;
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    // Likelihood calculations
    target += poisson_log_glm_lpmf(Y | to_matrix(mu), 0.0, mu_ones);
  }
  
  // Prior contributions
  target += lprior;
}
generated quantities {
  real b_Intercept = Intercept - dot_product(means_X, b);
}

--- END STANCODE ---

Saved to tasks/fixtures/fit5.rds

=== Fitting Model 6: CAR with GP ===
Fit 6 completed in 55.1 seconds
GAM observation formula:
y ~ (1 | series)

GAM process formula:
trend_y ~ gp(x) - 1


Family:
poisson 

Link function:
log 


Trend model:
CAR 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 6 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  /* compute a latent Gaussian process with squared exponential kernel
  * Args:
  *   x: array of continuous predictor values
  *   sdgp: marginal SD parameter
  *   lscale: length-scale parameter
  *   zgp: vector of independent standard normal variables
  * Returns:
  *   a vector to be added to the linear predictor
  */
  vector gp_exp_quad(data array[] vector x, real sdgp, vector lscale,
                     vector zgp) {
    int Dls = rows(lscale);
    int N = size(x);
    matrix[N, N] cov;
    if (Dls == 1) {
      // one dimensional or isotropic GP
      cov = gp_exp_quad_cov(x, sdgp, lscale[1]);
    } else {
      // multi-dimensional non-isotropic GP
      cov = gp_exp_quad_cov(x[ : , 1], sdgp, lscale[1]);
      for (d in 2 : Dls) {
        cov = cov .* gp_exp_quad_cov(x[ : , d], 1, lscale[d]);
      }
    }
    for (n in 1 : N) {
      cov[n, n] += 1e-12;
    }
    return cholesky_decompose(cov) * zgp;
  }
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> N_1;
  int<lower=1> M_1;
  array[N] int<lower=1> J_1;
  vector[N] Z_1_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N_trend, N_series_trend] real<lower=0> time_dis;
  int<lower=1> Dgp_1_trend;
  int<lower=1> Kgp_1_trend;
  int<lower=1> Nsubgp_1_trend;
  array[N_trend] int<lower=1> Jgp_1_trend;
  array[Nsubgp_1_trend] vector[Dgp_1_trend] Xgp_1_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
}
transformed data {
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
}
parameters {
  real Intercept;
  vector<lower=0>[M_1] sd_1;
  array[M_1] vector[N_1] z_1;
  vector<lower=0>[Kgp_1_trend] sdgp_1_trend;
  array[Kgp_1_trend] vector<lower=0>[1] lscale_1_trend;
  vector[Nsubgp_1_trend] zgp_1_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
}
transformed parameters {
  vector[N_1] r_1_1;
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(sdgp_1_trend | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += inv_gamma_lpdf(lscale_1_trend[1][1] | 1.494197, 0.056607);
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  lprior += student_t_lpdf(sd_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  vector[Nsubgp_1_trend] gp_pred_1_trend = gp_exp_quad(Xgp_1_trend,
                                                       sdgp_1_trend[1],
                                                       lscale_1_trend[1],
                                                       zgp_1_trend);
  mu_trend += gp_pred_1_trend[Jgp_1_trend];
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  for (j in 1 : N_lv_trend) {
    lv_trend[1, j] = scaled_innovations_trend[1, j];
  }
  for (j in 1 : N_lv_trend) {
    for (i in 2 : N_trend) {
      lv_trend[i, j] = pow(ar1_trend[j], time_dis[i, j]) * lv_trend[i - 1, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
  r_1_1 = (sd_1[1] * (z_1[1]));
}
model {
  ar1_trend ~ normal(0, 0.5);
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept;
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    for (n in 1 : N) {
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n];
    }
    // Likelihood calculations
    target += poisson_log_lpmf(Y | mu);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(zgp_1_trend);
  target += std_normal_lpdf(z_1[1]);
}
generated quantities {
  real b_Intercept = Intercept;
}

--- END STANCODE ---

Saved to tasks/fixtures/fit6.rds

=== Fitting Model 7: CAR with monotonic ===
Fit 7 completed in 42.1 seconds
GAM observation formula:
y ~ (1 | series)

GAM process formula:
trend_y ~ mo(income) - 1


Family:
poisson 

Link function:
log 


Trend model:
CAR 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 7 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  /* compute monotonic effects
  * Args:
  *   scale: a simplex parameter
  *   i: index to sum over the simplex
  * Returns:
  *   a scalar between 0 and rows(scale)
  */
  real mo(vector scale, int i) {
    if (i == 0) {
      return 0;
    } else {
      return rows(scale) * sum(scale[1 : i]);
    }
  }
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> N_1;
  int<lower=1> M_1;
  array[N] int<lower=1> J_1;
  vector[N] Z_1_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N_trend, N_series_trend] real<lower=0> time_dis;
  int<lower=1> Ksp_trend;
  int<lower=1> Imo_trend;
  array[N_trend] int Xmo_1_trend;
  array[Imo_trend] int<lower=1> Jmo_trend;
  vector[Jmo_trend[1]] con_simo_1_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
}
transformed data {
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
}
parameters {
  real Intercept;
  vector<lower=0>[M_1] sd_1;
  array[M_1] vector[N_1] z_1;
  simplex[Jmo_trend[1]] simo_1_trend;
  vector[Ksp_trend] bsp_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
}
transformed parameters {
  vector[N_1] r_1_1;
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += dirichlet_lpdf(simo_1_trend | con_simo_1_trend);
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  lprior += student_t_lpdf(sd_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  for (n in 1 : N_trend) {
    mu_trend[n] += (bsp_trend[1]) * mo(simo_1_trend, Xmo_1_trend[n]);
  }
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  for (j in 1 : N_lv_trend) {
    lv_trend[1, j] = scaled_innovations_trend[1, j];
  }
  for (j in 1 : N_lv_trend) {
    for (i in 2 : N_trend) {
      lv_trend[i, j] = pow(ar1_trend[j], time_dis[i, j]) * lv_trend[i - 1, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
  r_1_1 = (sd_1[1] * (z_1[1]));
}
model {
  ar1_trend ~ normal(0, 0.5);
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept;
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    for (n in 1 : N) {
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n];
    }
    // Likelihood calculations
    target += poisson_log_lpmf(Y | mu);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(z_1[1]);
}
generated quantities {
  real b_Intercept = Intercept;
}

--- END STANCODE ---

Saved to tasks/fixtures/fit7.rds

=== Fitting Model 8: Seasonal AR ===
Fit 8 completed in 44.7 seconds
GAM observation formula:
y ~ gp(x, k = 5)

GAM process formula:
trend_y ~ gp(temperature, k = 6) - 1


Family:
poisson 

Link function:
log 


Trend model:
AR 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 8 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  vector spd_gp_exp_quad(data array[] vector x, real sdgp, vector lscale) {
    int NB = dims(x)[1];
    int D = dims(x)[2];
    int Dls = rows(lscale);
    real constant = square(sdgp) * sqrt(2 * pi()) ^ D;
    vector[NB] out;
    if (Dls == 1) {
      // one dimensional or isotropic GP
      real neg_half_lscale2 = -0.5 * square(lscale[1]);
      constant = constant * lscale[1] ^ D;
      for (m in 1 : NB) {
        out[m] = constant * exp(neg_half_lscale2 * dot_self(x[m]));
      }
    } else {
      vector[Dls] neg_half_lscale2 = -0.5 * square(lscale);
      constant = constant * prod(lscale);
      for (m in 1 : NB) {
        out[m] = constant * exp(dot_product(neg_half_lscale2, square(x[m])));
      }
    }
    return out;
  }
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> Kgp_1;
  int<lower=1> Dgp_1;
  int<lower=1> NBgp_1;
  int<lower=1> Nsubgp_1;
  array[N] int<lower=1> Jgp_1;
  matrix[Nsubgp_1, NBgp_1] Xgp_1;
  array[NBgp_1] vector[Dgp_1] slambda_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  int<lower=1> Dgp_1_trend;
  int<lower=1> NBgp_1_trend;
  int<lower=1> Kgp_1_trend;
  int<lower=1> Nsubgp_1_trend;
  array[N_trend] int<lower=1> Jgp_1_trend;
  matrix[Nsubgp_1_trend, NBgp_1_trend] Xgp_1_trend;
  array[NBgp_1_trend] vector[Dgp_1_trend] slambda_1_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
}
transformed data {
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
}
parameters {
  real Intercept;
  vector<lower=0>[Kgp_1] sdgp_1;
  array[Kgp_1] vector<lower=0>[1] lscale_1;
  vector[NBgp_1] zgp_1;
  vector<lower=0>[Kgp_1_trend] sdgp_1_trend;
  array[Kgp_1_trend] vector<lower=0>[1] lscale_1_trend;
  vector[NBgp_1_trend] zgp_1_trend;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar12_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(sdgp_1_trend | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += inv_gamma_lpdf(lscale_1_trend[1][1] | 1.494197, 0.056607);
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  lprior += student_t_lpdf(sdgp_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += inv_gamma_lpdf(lscale_1[1][1] | 1.494197, 0.056607);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  vector[NBgp_1_trend] rgp_1_trend = sqrt(spd_gp_exp_quad(slambda_1_trend,
                                                          sdgp_1_trend[1],
                                                          lscale_1_trend[1]))
                                     .* zgp_1_trend;
  vector[Nsubgp_1_trend] gp_pred_1_trend = Xgp_1_trend * rgp_1_trend;
  mu_trend += gp_pred_1_trend[Jgp_1_trend];
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  for (i in 1 : 12) {
    lv_trend[i,  : ] = scaled_innovations_trend[i,  : ];
  }
  for (i in 13 : N_trend) {
    for (j in 1 : N_lv_trend) {
      lv_trend[i, j] = ar1_trend[j] * lv_trend[i - 1, j]
                       + ar12_trend[j] * lv_trend[i - 12, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  ar1_trend ~ normal(0, 0.5);
  ar12_trend ~ normal(0, 0.5);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[NBgp_1] rgp_1 = sqrt(spd_gp_exp_quad(slambda_1, sdgp_1[1],
                                                lscale_1[1]))
                           .* zgp_1;
    vector[Nsubgp_1] gp_pred_1 = Xgp_1 * rgp_1;
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept + gp_pred_1[Jgp_1];
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    // Likelihood calculations
    target += poisson_log_lpmf(Y | mu);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(zgp_1_trend);
  target += std_normal_lpdf(zgp_1);
}
generated quantities {
  real b_Intercept = Intercept;
}

--- END STANCODE ---

Saved to tasks/fixtures/fit8.rds

=== Fitting Model 9: Nonlinear with AR ===
Fit 9 completed in 35.5 seconds
GAM observation formula:
y ~ b1 * exp(b2 * x) 
b1 ~ 1
b2 ~ 1

GAM process formula:
trend_y ~ 0
<environment: 0x000001404359a048>


Family:
poisson 

Link function:
log 


Trend model:
AR 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 9 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> K_b1;
  matrix[N, K_b1] X_b1;
  int<lower=1> K_b2;
  matrix[N, K_b2] X_b2;
  vector[N] C_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
}
transformed data {
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
}
parameters {
  vector[K_b1] b_b1;
  vector[K_b2] b_b2;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += normal_lpdf(b_b1 | 1, 2);
  lprior += normal_lpdf(b_b2 | 0, 2);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  for (i in 1 : 1) {
    lv_trend[i,  : ] = scaled_innovations_trend[i,  : ];
  }
  for (i in 2 : N_trend) {
    for (j in 1 : N_lv_trend) {
      lv_trend[i, j] = ar1_trend[j] * lv_trend[i - 1, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  ar1_trend ~ normal(0, 0.5);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] nlp_b1 = rep_vector(0.0, N);
    vector[N] nlp_b2 = rep_vector(0.0, N);
    vector[N] mu;
    nlp_b1 += X_b1 * b_b1;
    nlp_b2 += X_b2 * b_b2;
    for (n in 1 : N) {
      mu[n] = ((nlp_b1[n] * exp(nlp_b2[n] * C_1[n])))
              + trend[obs_trend_time[n], obs_trend_series[n]];
    }
    // Likelihood calculations
    target += poisson_log_lpmf(Y | mu);
  }
  
  // Prior contributions
  target += lprior;
}
generated quantities {
  
}

--- END STANCODE ---

Saved to tasks/fixtures/fit9.rds

=== Fitting Model 10: Nested RE in observation ===
Fit 10 completed in 48.4 seconds
GAM observation formula:
count ~ x + (1 | site) + (1 | plot) 
biomass ~ x + (1 | site) + (1 | plot) 

GAM process formula:
trend_y ~ 0
<environment: 0x0000014044173d88>


Family:
gaussian 

Link function:
identity 


Trend model:
RW 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 10 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  
}
data {
  int<lower=1> N;
  int<lower=1> N_count;
  vector[N_count] Y_count;
  int<lower=1> K_count;
  matrix[N_count, K_count] X_count;
  int<lower=1> Kc_count;
  int<lower=1> N_biomass;
  vector[N_biomass] Y_biomass;
  int<lower=1> K_biomass;
  matrix[N_biomass, K_biomass] X_biomass;
  int<lower=1> Kc_biomass;
  int<lower=1> N_1;
  int<lower=1> M_1;
  array[N_count] int<lower=1> J_1_count;
  vector[N_count] Z_1_count_1;
  int<lower=1> N_2;
  int<lower=1> M_2;
  array[N_count] int<lower=1> J_2_count;
  vector[N_count] Z_2_count_1;
  int<lower=1> N_3;
  int<lower=1> M_3;
  array[N_biomass] int<lower=1> J_3_biomass;
  vector[N_biomass] Z_3_biomass_1;
  int<lower=1> N_4;
  int<lower=1> M_4;
  array[N_biomass] int<lower=1> J_4_biomass;
  vector[N_biomass] Z_4_biomass_1;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  array[N_count] int obs_trend_time_count;
  array[N_count] int obs_trend_series_count;
  array[N_biomass] int obs_trend_time_biomass;
  array[N_biomass] int obs_trend_series_biomass;
  vector[1] mu_ones_count;
  vector[1] mu_ones_biomass;
}
transformed data {
  matrix[N_count, Kc_count] Xc_count;
  vector[Kc_count] means_X_count;
  matrix[N_biomass, Kc_biomass] Xc_biomass;
  vector[Kc_biomass] means_X_biomass;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  for (i in 2 : K_count) {
    means_X_count[i - 1] = mean(X_count[ : , i]);
    Xc_count[ : , i - 1] = X_count[ : , i] - means_X_count[i - 1];
  }
  for (i in 2 : K_biomass) {
    means_X_biomass[i - 1] = mean(X_biomass[ : , i]);
    Xc_biomass[ : , i - 1] = X_biomass[ : , i] - means_X_biomass[i - 1];
  }
}
parameters {
  vector[Kc_count] b_count;
  real Intercept_count;
  real<lower=0> sigma_count;
  vector[Kc_biomass] b_biomass;
  real Intercept_biomass;
  real<lower=0> sigma_biomass;
  vector<lower=0>[M_1] sd_1;
  array[M_1] vector[N_1] z_1;
  vector<lower=0>[M_2] sd_2;
  array[M_2] vector[N_2] z_2;
  vector<lower=0>[M_3] sd_3;
  array[M_3] vector[N_3] z_3;
  vector<lower=0>[M_4] sd_4;
  array[M_4] vector[N_4] z_4;
  vector<lower=0>[N_lv_trend] sigma_trend;
  cholesky_factor_corr[N_lv_trend] L_Omega_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
}
transformed parameters {
  vector[N_1] r_1_count_1;
  vector[N_2] r_2_count_1;
  vector[N_3] r_3_biomass_1;
  vector[N_4] r_4_biomass_1;
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(Intercept_count | 3, 3, 2.5);
  lprior += student_t_lpdf(sigma_count | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(Intercept_biomass | 3, 2.7, 2.5);
  lprior += student_t_lpdf(sigma_biomass | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sd_1 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sd_2 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sd_3 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += student_t_lpdf(sd_4 | 3, 0, 2.5)
            - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  {
    matrix[N_lv_trend, N_lv_trend] L_Sigma = diag_pre_multiply(sigma_trend,
                                                               L_Omega_trend);
    scaled_innovations_trend = innovations_trend * L_Sigma';
  }
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  matrix[N_lv_trend, N_lv_trend] Sigma_trend = diag_pre_multiply(sigma_trend,
                                                                 L_Omega_trend);
  lv_trend[1,  : ] = scaled_innovations_trend[1,  : ];
  for (i in 2 : N_trend) {
    lv_trend[i,  : ] = lv_trend[i - 1,  : ]
                       + scaled_innovations_trend[i,  : ];
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
  r_1_count_1 = (sd_1[1] * (z_1[1]));
  r_2_count_1 = (sd_2[1] * (z_2[1]));
  r_3_biomass_1 = (sd_3[1] * (z_3[1]));
  r_4_biomass_1 = (sd_4[1] * (z_4[1]));
}
model {
  sigma_trend ~ exponential(2);
  L_Omega_trend ~ lkj_corr_cholesky(2);
  to_vector(innovations_trend) ~ std_normal();
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N_count] mu_count = rep_vector(0.0, N_count);
    vector[N_biomass] mu_biomass = rep_vector(0.0, N_biomass);
    mu_count += Intercept_count;
    mu_biomass += Intercept_biomass;
    for (n in 1 : N_count) {
      mu_count[n] += r_1_count_1[J_1_count[n]] * Z_1_count_1[n]
                     + r_2_count_1[J_2_count[n]] * Z_2_count_1[n];
    }
    for (i in 1 : N_count) {
      mu_count[i] += trend[obs_trend_time_count[i], obs_trend_series_count[i]];
    }
    for (n in 1 : N_biomass) {
      mu_biomass[n] += r_3_biomass_1[J_3_biomass[n]] * Z_3_biomass_1[n]
                       + r_4_biomass_1[J_4_biomass[n]] * Z_4_biomass_1[n];
    }
    for (i in 1 : N_biomass) {
      mu_biomass[i] += trend[obs_trend_time_biomass[i], obs_trend_series_biomass[i]];
    }
    // Likelihood calculations
    target += normal_id_glm_lpdf(Y_count | to_matrix(mu_count), 0.0, mu_ones_count, sigma_count);
    target += normal_id_glm_lpdf(Y_biomass | to_matrix(mu_biomass), 0.0, mu_ones_biomass, sigma_biomass);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(z_1[1]);
  target += std_normal_lpdf(z_2[1]);
  target += std_normal_lpdf(z_3[1]);
  target += std_normal_lpdf(z_4[1]);
}
generated quantities {
  real b_count_Intercept = Intercept_count
                           - dot_product(means_X_count, b_count);
  real b_biomass_Intercept = Intercept_biomass
                             - dot_product(means_X_biomass, b_biomass);
}

--- END STANCODE ---

Saved to tasks/fixtures/fit10.rds

=== Fitting Model 11: Correlated RE in trend ===
Fit 11 completed in 47.4 seconds
GAM observation formula:
y ~ x

GAM process formula:
trend_y ~ x + (x | site) - 1


Family:
poisson 

Link function:
log 


Trend model:
AR 


N series:
1 


N timepoints:
24 


Status:
2 chains, each with iter = 250 
  Total post-warmup draws = 500 

--- STANCODE for Fit 11 ---
// Generated with mvgam 2.0.0 using brms 2.22.9
functions {
  /* compute correlated group-level effects
  * Args:
  *   z: matrix of unscaled group-level effects
  *   SD: vector of standard deviation parameters
  *   L: cholesky factor correlation matrix
  * Returns:
  *   matrix of scaled group-level effects
  */
  matrix scale_r_cor(matrix z, vector SD, matrix L) {
    // r is stored in another dimension order than z
    return transpose(diag_pre_multiply(SD, L) * z);
  }
}
data {
  int<lower=1> N;
  array[N] int Y;
  int<lower=1> K;
  matrix[N, K] X;
  int<lower=1> Kc;
  int prior_only;
  int<lower=1> N_trend;
  int<lower=1> N_series_trend;
  int<lower=1> N_lv_trend;
  array[N_trend, N_series_trend] int times_trend;
  int<lower=1> K_trend;
  matrix[N_trend, K_trend] X_trend;
  vector[N_trend] Z_1_1_trend;
  vector[N_trend] Z_1_2_trend;
  array[N_trend] int<lower=1> J_1_trend;
  int<lower=1> N_1_trend;
  int<lower=1> M_1_trend;
  int<lower=1> NC_1_trend;
  array[N] int obs_trend_time;
  array[N] int obs_trend_series;
  vector[1] mu_ones;
}
transformed data {
  matrix[N, Kc] Xc;
  vector[Kc] means_X;
  // Factor loadings matrix: maps latent variables to observed series
  matrix[N_series_trend, N_lv_trend] Z = diag_matrix(rep_vector(1.0,
                                                                N_lv_trend));
  for (i in 2 : K) {
    means_X[i - 1] = mean(X[ : , i]);
    Xc[ : , i - 1] = X[ : , i] - means_X[i - 1];
  }
}
parameters {
  vector[Kc] b;
  real Intercept;
  vector[K_trend] b_trend;
  vector<lower=0>[M_1_trend] sd_1_trend;
  matrix[M_1_trend, N_1_trend] z_1_trend;
  cholesky_factor_corr[M_1_trend] L_1_trend;
  vector<lower=0>[N_lv_trend] sigma_trend;
  matrix[N_trend, N_lv_trend] innovations_trend;
  vector<lower=-1, upper=1>[N_lv_trend] ar1_trend;
}
transformed parameters {
  // Prior log-probability accumulator
  real lprior = 0;
  lprior += student_t_lpdf(sd_1_trend | 3, 0, 2.5)
            - 2 * student_t_lccdf(0 | 3, 0, 2.5);
  lprior += lkj_corr_cholesky_lpdf(L_1_trend | 1);
  lprior += student_t_lpdf(Intercept | 3, 1.8, 2.5);
  matrix[N_1_trend, M_1_trend] r_1_trend;
  vector[N_1_trend] r_1_1_trend;
  vector[N_1_trend] r_1_2_trend;
  r_1_trend = scale_r_cor(z_1_trend, sd_1_trend, L_1_trend);
  r_1_1_trend = r_1_trend[ : , 1];
  r_1_2_trend = r_1_trend[ : , 2];
  vector[N_trend] mu_trend = rep_vector(0.0, N_trend);
  for (n in 1 : N_trend) {
    mu_trend[n] += r_1_1_trend[J_1_trend[n]] * Z_1_1_trend[n]
                   + r_1_2_trend[J_1_trend[n]] * Z_1_2_trend[n];
  }
  matrix[N_trend, N_lv_trend] scaled_innovations_trend;
  scaled_innovations_trend = innovations_trend * diag_matrix(sigma_trend);
  // Latent variable trajectories over time
  matrix[N_trend, N_lv_trend] lv_trend;
  for (i in 1 : 1) {
    lv_trend[i,  : ] = scaled_innovations_trend[i,  : ];
  }
  for (i in 2 : N_trend) {
    for (j in 1 : N_lv_trend) {
      lv_trend[i, j] = ar1_trend[j] * lv_trend[i - 1, j]
                       + scaled_innovations_trend[i, j];
    }
  }
  // Final trend values for each time point and series
  matrix[N_trend, N_series_trend] trend;
  // Map latent variables to trend values via factor loadings
  for (i in 1 : N_trend) {
    for (s in 1 : N_series_trend) {
      trend[i, s] = dot_product(Z[s,  : ], lv_trend[i,  : ])
                    + mu_trend[times_trend[i, s]];
    }
  }
}
model {
  sigma_trend ~ exponential(2);
  to_vector(innovations_trend) ~ std_normal();
  ar1_trend ~ normal(0, 0.5);
  
  // Observation linear predictors and likelihoods (skipped when sampling from prior only)
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Xc * b;
    mu += Intercept;
    for (n in 1 : N) {
      mu[n] += trend[obs_trend_time[n], obs_trend_series[n]];
    }
    // Likelihood calculations
    target += poisson_log_glm_lpmf(Y | to_matrix(mu), 0.0, mu_ones);
  }
  
  // Prior contributions
  target += lprior;
  target += std_normal_lpdf(to_vector(z_1_trend));
}
generated quantities {
  real b_Intercept = Intercept - dot_product(means_X, b);
  corr_matrix[M_1_trend] Cor_1_trend = multiply_lower_tri_self_transpose(L_1_trend);
  vector<lower=-1, upper=1>[NC_1_trend] cor_1_trend;
  for (k_trend in 1 : M_1_trend) {
    for (j_trend in 1 : (k_trend - 1)) {
      cor_1_trend[choose(k_trend - 1, 2) + j_trend] = Cor_1_trend[j_trend, k_trend];
    }
  }
}

--- END STANCODE ---

Saved to tasks/fixtures/fit11.rds

=== ALL MODELS ATTEMPTED ===
Total time: 11.8 minutes

Fixture file sizes:
  fit1.rds: 1.14 MB
  fit2.rds: 2.34 MB
  fit3.rds: 0.88 MB
  fit4.rds: 2.78 MB
  fit5.rds: 0.80 MB
  fit6.rds: 0.64 MB
  fit7.rds: 0.42 MB
  fit8.rds: 0.62 MB
  fit9.rds: 1.29 MB
  fit10.rds: 2.73 MB
  fit11.rds: 0.52 MB

Successfully fitted: 11 models
Failed: 0 models

All available fixtures saved to tasks/fixtures/
Run readRDS('tasks/fixtures/fitN.rds') to load individual models
